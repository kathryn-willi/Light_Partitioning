---
output: html_document
editor_options: 
  chunk_output_type: console
---



# Data quality assessments

Note, also eval = F to save computation time

```{r, include = F}

library(tidyverse)
library(sf)
library(feather)
library(GGally)
library(mapview)
library(ggpmisc)
library(lubridate)
library(Metrics)
library(kableExtra)
library(broom)

knitr::opts_chunk$set(warning = F, message = F)
```


## Chl-a to biomass

While it is more common in coastal and oceanic research, inland water scientists
rarely measure water clarity constituents in the way that is most directly 
transferable to our research question. Ideally we would routinely measure concentrations of
algae biomass, non-algal particles
(including inorganic sediment and organic sediment, I like to call this
stuff dead suspended sediment, but I guess NAP is fine), and dissolved organic 
carbon. These constituents all alter light penetration in water, but they are 
mutually exclusive groups with no measurement overlap between algal particles and NAP
for example. However, this is not what we usually measure. Instead, we have rich 
datasets of things that could indicate our desired constituents. These map as basically.

- Chlorophyll-a -> proxy for algae biomass.
- Total suspended solids (tss) -> All suspended solids, subtract algae biomass = NAP
- DOC -> DOC!

That means we have to basically do one key calculation. Convert chl-a to biomass.
Then subtract that from tss and assume that is NAP. While this is a absurdly
simple calculation it is filled with dangers. The relationship between chl-a
and algae biomass depends on temperature and nutrients and species and is 
[not universal](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/2016GB005458).
Most studies focus on Chl:C ratios, but we are interested in Chl:Biomass ratio,
for which there are much fewer studies, though some studies below suggest 
a range of 0.005 to 0.1 Chl:biomass. (I need to find the C:Biomass study I used
forever ago.)

Papers that help:

  - https://aslopubs.onlinelibrary.wiley.com/doi/full/10.1002/lno.10338

  - https://pubs.usgs.gov/twri/twri9a7/twri9a7_7.4.pdf

  - https://www.researchgate.net/publication/230056019_Relationship_between_Chlorophyll-a_Concentration_and_Phytoplankton_Biomass_in_Several_Reservoirs_in_Czechoslovakia/link/5cb56c164585156cd79af804/download

  - https://archimer.ifremer.fr/doc/2005/publication-1172.pdf

### Approach

Our philosphy here is that we will use chl-a directly as a proxy for algal biomass
to minimize the number of transformations to this data, since we are primarily
interested in how algae alters light attenuation, regardless of how we estimate algae.
However, we still need to calculate Non-Algal Particle mass. For that we will
use a range of values of Chl:biomass and show the impact of picking a variety 
of ranges. 

*Caveats*

 - We don't have a true NAP to compare how accurate our approach is.
 
 - We do have Inorganic Sediment, but that is not the same thing as non-algal 
 particles, since it excludes particulate organic carbon. Still, where
 we have it, we will examine the relationship between NAP and TIS (total 
 inorganic sediment). 
 
 - Not entirely sure how we propogate this uncertainty downstream? Pick an average?



```{r}

in_vis <- read_feather('data/out/simul.feather')

no_sech <- read_feather('data/out/no_secchi.feather')

range <- c(50, 100, 200, 234)



#Couldn't think of a more clever way to multiply
#chl_a by the range of values, so just made
# dataframe 4 times bigger with new column called ratio. 
nap_test <- expand_grid(no_sech,chl_ratio = range) %>%
  mutate(power = ifelse(chl_ratio == 234, 0.57, 1),
         chl_a_biomass = exp(log(chl_ratio/1000)+log(chl_a)*power),
         tss_dead = tss-chl_a_biomass)


```

### Simple evaluations of conversion




#### Negative tss_dead

Probably the simplest way to see which ratios are more appropriate is to
look at how that impacts how many tss_dead observations are negative (impossible).

```{r}



nap_test %>%
  mutate(negative = ifelse(tss_dead < 0, 'negative', 'positive')) %>%
  group_by(negative,chl_ratio) %>%
  count() %>%
  pivot_wider(names_from = 'negative',values_from = 'n')  %>%
  mutate(percent_neg = negative/(positive+negative)*100) %>%
  knitr::kable()

```


Well, that sort of produces obvious results. Smaller ratios mean, less negative 
NAP estimates, but there is a big increase between 100-200, making me think the
"correct" ratio may be in there somewhere. 


#### Relationship between chl-a and tss_dead

If you recall from the previous section, there was a strong linear 
relationship between chl-a and tss across all sites and water types (r2 > 0.35).
One effect we'd expect to see with the tss_dead estimate is that this relationship
should decay. While there are reasons for chl-a to be correlated with tss (sediment
brings nutrients for example), chl-a also includes algal cells which are suspended
particles themselves. If this approach worked well, we should see weaker relationships
between tss_dead and chl-a


```{r, cache = T, fig.width = 7,fig.height = 7, fig.cap = "At low chl_ratios (10/20), there is really no change to the correlation between tss and chl_a, but at higher ratios (100/200), the relationship does breakdown some, though not completely"}


#Subset for plotting purposes
nap_test %>%
  #Remove negatives and very small numbers (ug/L of sediment is basically zero)
  filter(tss_dead > 0.001) %>%
  sample_frac(0.1) %>%
ggplot(., aes(chl_a,tss_dead,color = type)) +
  facet_wrap(~chl_ratio) + 
  geom_point() + 
  scale_x_log10() + 
  scale_y_log10() + 
  stat_poly_eq() + 
  ggthemes::theme_few() + 
  scale_color_manual(values = c('seagreen3','skyblue3','saddlebrown')) 

```


- What to do with this? 
- 234*chl^0.57 seems logical but still high correlation in lakes between tss/chl_a,
but that may be a real thing for lakes? (corr is actually higher with this approach)


## Data-driven qa/qc


We know that data in the water quality portal (and therfore in aquasat) comes
with inherent biases and problems that are a natural part of aggregated massive
datasets like the WQP. So how do we evaluate data quality in this context? Here
we assume that some answers about data quality can be found in the original 
WQP data context including analytical and field methods data as well as 
information about which organizations collected the sample. 

The sketchy part? We don't have a systematic way to understand if data is unreliable
except for... The contributions of each our constituents to clarity should be limited
by physical limits of how light interacts with particles, algae, and DOC. So if 
we build a model of light extinction as a function of f(doc, chl_a, tss_dead), the
worst residuals on that model, might inform data quality. Then we can subset data
to only include data of the highest quality. 


### Extracting methods

AquaSat chose (I) to remove methods info from the raw wqp data, but we kept it
in a second file that we already downloaded. We just need to manipulate that data
to play nice with our simultaneous observation data. 


```{r, eval = F}

#This chunk is slow and therefore not run in bookdown. 

#get WQP methods for post-hoc investigation of errors


simul_methods <-  read_csv('data/in/aq_situ/in-situ/wqp_long_with_methods.csv') %>%
  dplyr::filter(SiteID %in% in_vis$SiteID)

length(is.na(simul_methods$characteristicName))

simul_methods_time_fix <- simul_methods %>%
  mutate(time = as.character(format(date_time, '%H:%M:%S')), 
         date_only=ifelse(is.na(date_time) | time == '00:00:00',T,F), 
         date_unity = ymd_hms(ifelse(date_only == T,
                              paste(date,'12:00:00'),
                              as.character(date_time)),
                              tz='UTC')) %>%
         mutate(time = as.character(format(date_unity, '%H:%M:%S')),
         date_unity = ifelse(time == '00:00:00',
          date_unity + hours(12),
          date_unity) %>% #Convert back to poxict ()
           as.POSIXct(.,origin='1970-01-01 00:00:00',tz='UTC')) %>%
    #remove any time stamps that are NA
  filter(!is.na(date_unity)) %>%
  filter(year(date_unity) > 1900,
         year(date_unity) <= year(Sys.Date())) %>%
  #select(SiteID,date,characteristicName) %>%
  as_tibble() %>%
  dplyr::select(-date_only) %>%
  mutate(harmonized_parameter = gsub('chl.a','chl_a',harmonized_parameter))



simul_vis_long <- in_vis %>%
  pivot_longer(cols = chl_a:tss,names_to = 'harmonized_parameter') 




simul_vis_methods <- full_join(simul_methods_time_fix,simul_vis_long) 


#Fast
feather::write_feather(simul_vis_methods, 'data/out/simul_methods.feather')
# Reproducible
write_csv(simul_vis_methods,'data/out/simul_methods.csv')
```



### Light attenuation model exploration

Model assumptions

- Not searching for intercept assuming observed 0.15 coefficient for intercept (pure water attenuation)

- For now, not doing the middle 2.5-97.5% of data, can add back in.

- Normality assumptions aren't fully met



```{r, warning = F, cache = T, fig.cap = 'modelled light extinction coefficient versus observed, red line is 1:1 line and blue is line of best fit, R2 hardly varies between chl-a conversion approaches.'}


nap_est_no_secchi <- nap_test %>%
  ungroup() %>%
  filter(tss_dead > 0.01,
         secchi < 15 | is.na(secchi)) %>%
  mutate(secchi = ifelse(secchi < 0.1,0.1,secchi),
        kd = (1/(secchi)))



write_feather(nap_est_no_secchi %>%
                filter(chl_ratio == 234),'data/out/no_secchi_clean.feather')



nap_est <- nap_est_no_secchi %>%
  filter(!is.na(secchi))




k_w <- 1/1.5/max(nap_est$secchi)


kd_mod <- function(df){
  mod <- lm((kd-k_w)  ~ 0 + tss_dead + doc + chl_a, data = df)
}


kd_resid_extract <- function(df,mod){
  df <- df %>%
    mutate(residuals = mod$residuals,
           pred = mod$fitted.values + k_w)
}

# nap_est <- nap_est %>%
#   filter(SiteID %in% fine_sites$SiteID) 


nap_mods <- group_by(nap_est,chl_ratio) %>%
  nest() %>%
  mutate(mods = map(data,kd_mod),
         data = map2(data, mods, kd_resid_extract))

mod234 <- nap_mods %>%
  dplyr::filter(chl_ratio == 234)



nap_resid <- nap_mods %>%
  dplyr::select(-mods) %>%
  unnest(data) %>%
  mutate(ratio_rmse = paste('ratio =',chl_ratio,', R2 =', round(cor(pred,kd)^2,2)),
         year = year(date_unity))


nap_resid %>%
  sample_frac(0.2) %>%
  ggplot(., aes(kd,pred, color = year(date_unity))) + 
  geom_point(shape = 1) + 
  facet_wrap(~ratio_rmse) + 
  ggthemes::theme_few() + 
  xlab('kd (1/secchi)') +
  ylab('predicted kd') +
  scale_x_log10() + 
  scale_y_log10() +
  scale_color_viridis_c() + 
  stat_smooth(method = 'lm',se = F, color = 'black') +
  geom_abline(intercept = 0, slope = 1, col = 'red') 





```





### Variation in slopes w/ different chl biomass ratios

- Do all our painstaking decisions make a difference for model slopes?

- (They didn't impact model RMSE very much)

- No, they don't change slopes all that much either. 



```{r}

nap_slopes <- nap_mods %>%
  select(-data) %>%
  mutate(glance = map(mods, tidy)) %>%
  unnest(glance) %>%
  select(-mods,-std.error,-statistic) %>%
  pivot_wider(names_from = 'term', values_from = 'estimate')



knitr::kable(nap_slopes) %>%
  kable_paper() %>%
  scroll_box(width = '100%', height = '600px') %>%
  kable_styling(bootstrap_options = 'striped', full_width = )
```




# Data prep and model refinement

In the data QA/QC step we tried various ways to make some wise choices about what 
data to include in this analysis. Unfortunately, with data, coming from such disparate sources
we could make no series of wise choices on what data to keep and what to remove without
the choices, ultimately being arbitrary. We additionally explored how the chl-a to biomass
ratio conversion impacted the outcome of our models, concluding that the variable
ratio of 234^0.5 was a fine choice with little impact to modeled slopes. 

So what additional refinement do we need. Well we would like to explore a few things:

  1. How much can models be improved by restricting to the most strict method collection types? 
 
  2. How stable are the coefficients for each parameter across water body types,
  geography, and when random subsets are taken? 

## Exploring Data and Model Results for Systematic Problems 

### Analytical Methods and Error Characterization

```{r, fig.width = 12, fig.height = 8}


simul_vis_methods <- feather::read_feather('data/out/simul_methods.feather')



methods_summarizer <- function(param = 'tss'){
  
  methods <- simul_vis_methods %>%
    filter(harmonized_parameter == param) 
    inner_join(nap_resid %>%
                 ungroup() %>%
                 filter(chl_ratio == 234) %>%
                 select(SiteID,date_unity,residuals,pred,kd)) 

  
  method_plot <- methods %>%
    group_by(analytical_method) %>%
    add_count() %>%
    mutate(method_count = paste('n =',n,'-',analytical_method)) %>%
    ggplot(., aes(kd,pred,color = method_count)) + 
    #geom_point(shape = 1) + 
    ggthemes::theme_few() + 
    xlab('kd (1.4/secchi)') +
    ylab('predicted kd') +
    scale_x_log10() + 
    scale_y_log10() + 
    stat_smooth(method = 'lm',se=F) +
    geom_abline(intercept = 0, slope = 1, col = 'black')
  
  
  method_error <- methods %>%
    group_by(analytical_method) %>%
    summarize(rmse = rmse(kd,pred),
              resid_cv = sd(residuals)/mean(residuals),
              n = n(),
              resid_se = sd(residuals)/(n^0.5),
              mdae = mdae(kd,pred),
              impact = (n*rmse)/nrow(.)) %>%
    arrange(-impact)  %>%
    mutate(across(where(is.numeric), ~(round(.x, 2))),
           param = param)
  
  name_error <- methods %>%
    group_by(characteristicName) %>%
    summarize(rmse = rmse(kd,pred),
              resid_cv = sd(residuals)/mean(residuals),
              n = n(),
              resid_se = sd(residuals)/(n^0.5),
              mdae = mdae(kd,pred),
              impact = (n*rmse)/nrow(.)) %>%
    arrange(-impact) %>%
    mutate(across(where(is.numeric), ~(round(.x, 2))),
           param = param)
  
  
  name_plot <- methods %>%
    group_by(characteristicName) %>%
    add_count() %>%
    mutate(name_count = paste('n =',n,'-',characteristicName)) %>%
    ggplot(., aes(kd,pred,color = name_count)) + 
    #geom_point(shape = 1) + 
    ggthemes::theme_few() + 
    xlab('kd (1.4/secchi)') +
    ylab('predicted kd') +
    scale_x_log10() + 
    scale_y_log10() + 
    stat_smooth(method = 'lm',se=F) +
    geom_abline(intercept = 0, slope = 1, col = 'black')
  
  
  
  return(list(method_error,name_error,method_plot,name_plot,methods))
  
}

chl_errors <- methods_summarizer('chl_a')
doc_errors <- methods_summarizer('doc')
tss_errors <- methods_summarizer('tss')
secchi_errors <- methods_summarizer('secchi')

method_errors <- rbind(chl_errors[[1]],doc_errors[[1]],
                    tss_errors[[1]],secchi_errors[[1]])



knitr::kable(method_errors) %>%
  kable_paper() %>%
  scroll_box(width = '100%', height = '600px') %>%
  kable_styling(bootstrap_options = 'striped', full_width = )
```


### Param Name Errors 

```{r}
name_errors <- rbind(chl_errors[[2]],doc_errors[[2]],
                    tss_errors[[2]],secchi_errors[[2]])

knitr::kable(name_errors) %>%
  kable_paper() %>%
  scroll_box(width = '100%', height = '600px') %>%
  kable_styling(bootstrap_options = 'striped', full_width = )


```


### Do methods predict residuals?


#### Chl-a methods


- No. 

```{r}

library(rpart)
library(rpart.plot)
chl_methods <- chl_errors[[5]]

tss_methods <- tss_errors[[5]]

doc_methods <- doc_errors[[5]]

secchi_methods <- secchi_errors[[5]]

# write_csv(chl_methods, 'data/out/chl_methods.csv')
# write_csv(tss_methods, 'data/out/tss_methods.csv')
# write_csv(doc_methods, 'data/out/doc_methods.csv')
# write_csv(secchi_methods, 'data/out/secchi_methods.csv')
# 




chl_vars <- chl_methods %>%
  dplyr::select(residuals,lat, long,characteristicName, kd, analytical_method) %>%
  dplyr::filter(!is.na(residuals),!is.na(lat),!is.na(long)) %>%
  mutate(across(characteristicName:analytical_method,
                ~ifelse(is.na(.),'unknown',.))) %>%
  mutate(residuals_bin = cut(abs(residuals/kd),
                             breaks = quantile(abs(residuals/kd),c(0,0.95,0.99,1)))) %>%
  na.omit(.)





# chl_rando <- randomForest(residuals ~ ., data = chl_vars,
#                           ntree = 500,
#                           importance = T,
#                           nPerm = 20)
# 


cart_mod <- rpart(residuals_bin ~ ., data = chl_vars %>% 
                    dplyr::select(-residuals,-kd),
                  cp = 0.01) # CP is a tuning knob for tree complexity. 
cart_mod

rpart.plot(cart_mod, type = 2, clip.right.labs = F,
           branch = 0.3)


```


# Model variations


## Subsetting only the most common methods

Which, unfortunately, includes a ton of methods labeled = NA. 


```{r}


nap_234 <- nap_est %>%
  filter(chl_ratio == 234) %>%
  mutate(methods = 'all')


strict_methods <- simul_vis_methods %>%
    filter(harmonized_parameter == 'tss' & is.na(analytical_method) & is.na(characteristicName))
    filter(characteristicName %in% c('Chlorophyll a','Chlorophyll a, corrected for pheophytin',
                                     'Organic carbon', 'Depth, Secchi disk depth'),
           analytical_method %in% c('MONOCHROMATIC; SPECTROPHOTOMETRIC','10200 H ~ Chlorophyll a-b-c Determination','Total Organic Carbon by Combustion','5310 B ~ Total Organic Carbon by Combustion-Infrared Method',
                                    'UV OR HEATED PERSULFATE OXIDATION','WET OXIDATION METHOD')) 
  filter(harmonized_parameter == 'tss' & analytical_method == NA & characteristicName == NA) %>%
  select(date_unity,SiteID) %>%
  distinct(.) %>%
  inner_join(nap_234) %>%
  mutate(methods = 'strict')




strict_v_loose <- bind_rows(strict_methods,nap_234) %>%
  group_by(methods) %>%
  nest() %>%
  mutate(mods = map(data,kd_mod),
         data = map2(data, mods, kd_resid_extract))



method_resid <- strict_v_loose %>%
  dplyr::select(-mods) %>%
  unnest(data) %>%
  mutate(ratio_rmse = paste('methods =',methods,', R2 =', round(cor(pred,kd)^2,2)),
         year = year(date_unity))


method_resid %>%
  sample_frac(0.2) %>%
  ggplot(., aes(kd,pred, color = year(date_unity))) + 
  geom_point(shape = 1) + 
  facet_wrap(~ratio_rmse) + 
  ggthemes::theme_few() + 
  xlab('kd (1/secchi)') +
  ylab('predicted kd') +
  scale_x_log10() + 
  scale_y_log10() +
  scale_color_viridis_c() + 
  stat_smooth(method = 'lm',se = F, color = 'black') +
  geom_abline(intercept = 0, slope = 1, col = 'red') 


```


