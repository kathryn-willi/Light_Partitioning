[["index.html", "1 Light Partitioning", " 1 Light Partitioning This bookdown documents the harmonization process for parameters from the Water Quality Portal. "],["download-process.html", "2 Download process", " 2 Download process 2.0.1 Catalogue existing data The download process begins by cataloging the existing data that is available. We start out using the following parameters and parameter codes for retrieving data: chlorophyll: “Chlorophyll” “Chlorophyll A” “Chlorophyll a” “Chlorophyll a (probe relative fluorescence)” “Chlorophyll a (probe)” “Chlorophyll a - Periphyton (attached)” “Chlorophyll a - Phytoplankton (suspended)” “Chlorophyll a, corrected for pheophytin” “Chlorophyll a, free of pheophytin” “Chlorophyll a, uncorrected for pheophytin” “Chlorophyll b” “Chlorophyll c” “Chlorophyll/Pheophytin ratio” secchi: “Depth, Secchi disk depth” “Depth, Secchi disk depth (choice list)” “Secchi Reading Condition (choice list)” “Secchi depth” “Water transparency, Secchi disc” doc: “Organic carbon” “Total carbon” “Hydrophilic fraction of organic carbon” “Non-purgeable Organic Carbon (NPOC)” tss: “Total suspended solids” “Total Suspended Particulate Matter” 2.0.2 Maps of data spread within the contiguous US: Maps are presented below with counts of records across a grid. The grid is how records are grouped in download requests to the Water Quality Portal. Florida is mapped separately because of its high concentration of values. Note: 1) the top four grid cells in the FL map are included in both maps, 2) the counts here are for raw data that are not filtered for simultaneous records. Code # Combine counts in each grid_id with the grid polygons grid_counts &lt;- left_join(x = global_grid, y = site_counts %&gt;% count(grid_id), by = c(&quot;id&quot; = &quot;grid_id&quot;)) %&gt;% st_transform(crs = 9311) state_selection &lt;- states(progress_bar = FALSE) %&gt;% filter(!NAME %in% c(&quot;Alaska&quot;, &quot;Hawaii&quot;, &quot;American Samoa&quot;, &quot;Guam&quot;, &quot;Puerto Rico&quot;, &quot;United States Virgin Islands&quot;, &quot;Commonwealth of the Northern Mariana Islands&quot;)) %&gt;% st_transform(crs = 9311) ## Retrieving data for the year 2020 Code non_fl_map &lt;- ggplot() + geom_sf(data = grid_counts %&gt;% filter(!id %in% c(#10847:10850, 10668, 10669, 10670, 10489, 10490, 10491, 10309, 10310)), aes(fill = n)) + geom_sf(data = state_selection %&gt;% filter(NAME != &quot;Florida&quot;), fill = NA, color = &quot;white&quot;) + # geom_sf_text(data = grid_counts, aes(label = id)) + xlab(NULL) + ylab(NULL) + coord_sf(xlim = c(min(st_coordinates(state_selection)[,&quot;X&quot;]), max(st_coordinates(state_selection)[,&quot;X&quot;])), ylim = c(min(st_coordinates(state_selection)[,&quot;Y&quot;]), max(st_coordinates(state_selection)[,&quot;Y&quot;]))) + scale_fill_viridis_c(&quot;Record count&quot;) + theme_bw() non_fl_map Code fl_states &lt;- state_selection %&gt;% filter(NAME %in% c(&quot;Florida&quot;, &quot;Georgia&quot;, &quot;Alabama&quot;)) fl_map &lt;- ggplot() + geom_sf(data = grid_counts %&gt;% filter(id %in% c(10847:10850, 10668, 10669, 10670, 10489, 10490, 10491, 10309, 10310)), aes(fill = n)) + geom_sf(data = fl_states, fill = NA, color = &quot;black&quot;) + # geom_sf_label(data = grid_counts, aes(label = id)) + xlab(NULL) + ylab(NULL) + coord_sf(xlim = c(min(st_coordinates(fl_states)[,&quot;X&quot;]), max(st_coordinates(fl_states)[,&quot;X&quot;])), ylim = c(min(st_coordinates(fl_states)[,&quot;Y&quot;]), max(st_coordinates(fl_states)[,&quot;Y&quot;]))) + scale_fill_viridis_c(&quot;Record count&quot;) + theme_bw() fl_map "],["pre-harmonization-decision-process.html", "3 Pre-harmonization decision process", " 3 Pre-harmonization decision process 3.0.1 0. Initial dataset At the start of the preharmonization process the WQP dataset contains 15.07 million rows. 3.0.2 1. Remove duplicates The first filtering step is to remove any duplicated records present in the dataset. This results in dropping 3.02 million rows for a record count of 12.06 million. 3.0.3 2. Missing results Next missing results are dropped from the dataset. 499.56 thousand rows are dropped, resulting in a final count of 11.56 million. 3.0.4 2. Filter status We next filter the ResultStatusIdentifier column to include only the following statuses: \"Accepted\" \"Final\" \"Historical\" \"Validated\" \"Preliminary\" NA 43.53 thousand rows are dropped from the dataset leaving it with 11.51 million remaining. 3.0.5 3. Filter media Next the ActivityMediaSubdivisionName is filtered to only include only the following media: \"Surface Water\" \"Water\" \"Estuary\" NA 24.29 thousand rows are dropped and 11.49 million remain. 3.0.5.1 4. Location type The final step in pre-harmonization is filtering out any ResolvedMonitoringLocationTypeName that is not \"Estuary\", \"Lake, Reservoir, Impoundment\", or \"Stream\". After dropping 124.4 thousand rows the pre-harmonization dataset is complete with 11.36 million. "],["chlorophyll-harmonization-process-strict-version.html", "4 Chlorophyll harmonization process (strict version)", " 4 Chlorophyll harmonization process (strict version) 4.0.1 0. Initial dataset After the preharmonization process the chlorophyll-only WQP dataset contains 3.41 million rows. 4.0.2 1. Filter for water media The first step in chla harmonization is to ensure that the media type for the data is \"water\" or \"Water\". This should just be a precautionary step: 0 rows are removed. The final row count after this is 3.41 million. 4.0.3 2. Keep only chlorophyll parameters The next step is to ensure that there are only parameter names related to chlorophyll a in the dataset. We retain the following values: Chlorophyll a Chlorophyll a (probe relative fluorescence) Chlorophyll a, corrected for pheophytin Chlorophyll a (probe) Chlorophyll a, free of pheophytin Chlorophyll a - Phytoplankton (suspended) 1.29 million rows are removed and 2.12 million rows remain. 4.0.4 3. Remove fails and other missing data In this step we filter out records based on indications that they have failed data for some reason. We screen the following columns: ActivityCommentText, ResultLaboratoryCommentText, ResultCommentText, and ResultMeasureValue. Examples of text that results in a dropped record includes (but is not limited to): \"fail\", \"suspect\", \"error\", \"beyond accept\", \"interference\", \"questionable\", \"problem\", \"violation\", \"rejected\", \"no data\". Specific target text varies by column. 84.07 thousand rows are removed and 2.04 million rows remain. 4.0.5 4. Clean MDLs In this step method detection limits (MDLs) are used to clean up the reported values. When a numeric value is missing for the data record (i.e., NA or text that became NA during an as.numeric call) we check for non-detect language in the ResultLaboratoryCommentText, ResultCommentText, ResultDetectionConditionText, and ResultMeasureValue columns. This language can be \"non-detect\", \"not detect\", \"non detect\", \"undetect\", or \"below\". If non-detect language exists then we use the DetectionQuantitationLimitMeasure.MeasureValue column for the MDL, otherwise if there is a &lt; and a number in the ResultMeasureValue column we use that number instead. We then use a random number between 0 and 0.5 * MDL as the record’s value moving forward. This should not result in a change in rows but we still check: 0 rows are removed. The final row count after this is 2.04 million. 4.0.6 5. Clean approximate values Step 5 involves a similar process as for MDL cleaning. We flag “approximated” values in the dataset. The ResultMeasureValue column gets checked for all three of the following conditions: Numeric-only version of the column is still NA after MDL cleaning The original column text contained a number Any of ResultLaboratoryCommentText, ResultCommentText, or ResultDetectionConditionText match this regular expression, ignoring case: \"result approx|RESULT IS APPROX|value approx\" We then use the approximate value as the record’s value moving forward. This should not result in a change in rows but we still check: 0 rows are removed. The final row count after this is 2.04 million. 4.0.7 6. Clean values with “greater than” data Step 6 is similar to the MDL and approximate value cleaning processes, and follows the approximate cleaning process most closely. The goal is to clean up values that were entered as “greater than” some value. The ResultMeasureValue column gets checked for all three of the following conditions: Numeric-only version of the column is still NA after MDL &amp; approximate cleaning The original column text contained a number The original column text contained a &gt; We then use the “greater than” value (without &gt;) as the record’s value moving forward. This should not result in a change in rows but we still check: 0 rows are removed. The final row count after this is 2.04 million. 4.0.8 7. Harmonize record units The next step in chla harmonization is working with the units of the WQP records. These can vary widely. We create the following conversion table, which is used to translate units provided in WQP into micrograms/L: units conversion mg/l 1e+03 mg/L 1e+03 ppm 1e+03 ug/l 1e+00 ug/L 1e+00 mg/m3 1e+00 ppb 1e+00 mg/cm3 1e+06 ug/ml 1e+03 mg/ml 1e+06 ppt 1e+06 This should not result in a change in rows but we still check: 1.271^{5} rows are removed. The final row count after this is 1.91 million. 4.0.9 8. Clean depth data The ActivityDepthHeightMeasure.MeasureValue column is the site of our next harmonization step. We want to both harmonize the units (ActivityDepthHeightMeasure.MeasureUnitCode) used in the dataset and set limits for depths from which we’ll accept data. We’ll use a conversion table as with the previous units harmonization step: depth_units depth_conversion in 0.0254 ft 0.3048 feet 0.3048 cm 0.0100 m 1.0000 meters 1.0000 Once the units have been standardized we’ll make sure that the numeric depth value is within +/-2m OR the raw character version indicates something similar. We also keep NA depths to avoid losing a ton of records. This is how it’s coded: Code converted_units_chla %&gt;% left_join(x = ., y = depth_unit_conversion_table, by = c(&quot;sample_depth_unit&quot; = &quot;depth_units&quot;)) %&gt;% mutate(harmonized_depth_value = as.numeric(sample_depth) * depth_conversion, harmonized_depth_unit = &quot;m&quot;) %&gt;% filter(abs(harmonized_depth_value) &lt;= 2 | sample_depth %in% c(&quot;0-2&quot;, &quot;0-0.5&quot;)| is.na(sample_depth)) Through our depth filtering we lose 121.13 thousand rows and have 1.79 million remaining. 4.0.10 9. Filter based on analytical method Our next step is to aggregate chla analytical methods into groups and then filter out methods that may have been erroneously added, were unclear, or which don’t meet our needs. We accomplish this using an external match table csv file that is joined to the dataset. Methods that are NA for their aggregated grouping or which are \"unlikely\" to be accurate methods are dropped. This process drops 2648 rows leaving 1.79 million remaining. 4.0.11 10. Filter based on fraction type The final step in our chla harmonization is filtering based on the ResultSampleFractionText column. We assign fractions into two categories based on whether the fraction text makes sense or not and then retain only those records that have a fraction with \"Makes sense\". Fractions included in this are \"Non-Filterable (Particle)\", \"Suspended\", \"Non-filterable\", \"&lt;Blank&gt;\", and \"Acid Soluble\". This process drops 116.99 thousand rows leaving 1.67 million remaining in the final harmonized chla dataset. "],["doc-harmonization-process-strict-version.html", "5 DOC harmonization process (strict version)", " 5 DOC harmonization process (strict version) 5.0.1 0. Initial dataset After the preharmonization process the DOC-only WQP dataset contains 2.15 million rows. 5.0.2 1. Filter for water media The first step in DOC harmonization is to ensure that the media type for the data is \"water\" or \"Water\". This should just be a precautionary step: 0 rows are removed. The final row count after this is 2.15 million. 5.0.3 2. Remove fails and other missing data In this step we filter out records based on indications that they have failed data for some reason. We screen the following columns: ActivityCommentText, ResultLaboratoryCommentText, ResultCommentText, ResultMeasureValue, and ResultDetectionConditionText. Examples of text that results in a dropped record includes (but is not limited to): \"fail\", \"suspect\", \"error\", \"beyond accept\", \"interference\", \"questionable\", \"problem\", \"violation\", \"rejected\", \"no data\". Specific target text varies by column. 72.25 thousand rows are removed and 2.08 million rows remain. 5.0.4 3. Clean MDLs In this step method detection limits (MDLs) are used to clean up the reported values. When a numeric value is missing for the data record (i.e., NA or text that became NA during an as.numeric call) we check for non-detect language in the ResultLaboratoryCommentText, ResultCommentText, ResultDetectionConditionText, and ResultMeasureValue columns. This language can be \"non-detect\", \"not detect\", \"non detect\", \"undetect\", or \"below\". If non-detect language exists then we use the DetectionQuantitationLimitMeasure.MeasureValue column for the MDL, otherwise if there is a &lt; and a number in the ResultMeasureValue column we use that number instead. We then use a random number between 0 and 0.5 * MDL as the record’s value moving forward. This should not result in a change in rows but we still check: 0 rows are removed. The final row count after this is 2.08 million. 5.0.5 4. Clean approximate values Step 4 involves a similar process as for MDL cleaning. We flag “approximated” values in the dataset. The ResultMeasureValue column gets checked for all three of the following conditions: Numeric-only version of the column is still NA after MDL cleaning The original column text contained a number Any of ResultLaboratoryCommentText, ResultCommentText, or ResultDetectionConditionText match this regular expression, ignoring case: \"result approx|RESULT IS APPROX|value approx\" We then use the approximate value as the record’s value moving forward. This should not result in a change in rows but we still check: 0 rows are removed. The final row count after this is 2.08 million. 5.0.6 5. Harmonize record units The next step in doc harmonization is working with the units of the WQP records. These can vary widely. We create the following conversion table, which is used to translate units provided in WQP into milligrams/L: units conversion mg/L 1.000e+03 mg/l 1.000e+03 ppm 1.000e+03 ug/l 1.000e+00 ug/L 1.000e+00 mg/m3 1.000e+00 ppb 1.000e+00 mg/cm3 1.000e+06 ug/ml 1.000e+03 mg/ml 1.000e+06 ppt 1.000e-06 umol/L 6.008e+01 We also limit values to less than 50 mg/L to ensure realistic data. 47.11 thousand rows are removed. The final row count after this is 2.03 million. 5.0.7 6. Filter based on analytical method Our next step is to aggregate doc analytical methods into groups and then filter out methods that may have been erroneously added, were unclear, or which don’t meet our needs. Methods that were NA or were grouped as \"Ambiguous\" or \"Carbonaceous Analyzer\" are dropped. This process drops 1.032728^{6} rows leaving 1 million remaining. 5.0.8 7. Filter based on fraction type The final step in our doc harmonization is filtering based on the ResultSampleFractionText column. We keep records with the following values in this column: \"Dissolved\", \"Filtered, lab\", \"Filterable\", \"Filtered, field\". This process drops 657.28 thousand rows leaving 0.34 million remaining in the final harmonized doc dataset. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
